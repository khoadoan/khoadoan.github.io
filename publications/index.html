<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Khoa D Doan


  | publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css">


<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
<link rel="stylesheet" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">

<!-- Code Syntax Highlighting -->
<!-- Very long loading using this file, so we swap -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->
<link rel="stylesheet" href="https://combinatronics.io/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<!-- 
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 -->
<link rel="icon" href="assets/img/icon.png">
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5E8HDGL2HV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-5E8HDGL2HV');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <div class="navbar-brand social">
        <div class="logo">
          <a href="https://mail-research.com"><img width="" height="30px" alt="blank" src="/assets/img/logo/logo-mail-v2.png" /></a>
        </div>
        <!-- <div class="logo-mobile">
          <a href=""><img width="32px" height="20px" alt="blank" src="/assets/img/logo/logo-mail-v2.png" /></a>
        </div> -->
      </div>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <!-- <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li> -->
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research">
                research
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/team">
                group
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/photos/">
                photos
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/contact">
                contact
                
              </a>
          </li>
          
          
          
          <!-- <li class="nav-item">
              <a class="nav-link" href="/assets/pdf/khoadoan_cv_current.pdf">
                 CV
              </a>
          </li> -->

          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <!-- <h1 class="post-title">publications</h1> -->
    <p class="post-description"></p>
  </header>

  <article>
    <div style="font-style: normal">
<div class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
    <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr> Majority of work done or significant contribution by MAIL/SAIL members!
</div>

<div>
<a class="btn btn-sm" role="button" style="color: black; border: 1px solid black; font-style: normal; padding: 0.0rem 0.0rem 0.0rem 0.0rem;">Submission History</a> shows the venues where the work has been submitted (ðŸ™ƒ including <strong>rejections</strong> ðŸ™ƒ). I hope some of my poor rejection/failure histories (record now is 10 rejections ðŸ˜…) give you some encouragement to try again when things don't work out (don't give up -- good work doesn't need to be rushed)!
</div>

<div style="padding-top:1rem; color: red">
publications by categories in reversed chronological order. An up-to-date list is available on <em><a href="https://scholar.google.com/citations?user=Zz2hMgcAAAAJ&amp;hl=en" style="color:blue; font-size:15px">Google Scholar</a></em>.
</div>

<hr />

<div class="publications">
  
    <!-- <h2 class="pyear">2025&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2025merging3d" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    Tuan A Tran,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Duy MH Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Chau H Tran</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and  others
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent advances in 3D point cloud transformers have led to state-of-the-art results in tasks such as semantic segmentation and reconstruction. However, these models typically rely on dense token representations, incurring high computational and memory costs during training and inference. In this work, we present an efficient token merging strategy that drastically reduces the token count by up to 90â€“95\% while preserving competitive performance. Our approach estimates token importance by leveraging spatial structures within the 3D point cloud, enabling aggressive token reduction with minimal degradation in accuracy. This finding challenges the prevailing assumption that more tokens inherently yield better performance and highlights that many current models are over-tokenized and under-optimized for scalability. We validate our method across multiple 3D vision tasks and show consistent improvements in computational efficiency. Our ongoing work will release code and detailed benchmarks to support reproducibility and further system-level exploration of efficient foundation models for 3D data.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2025merging3d</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Tuan A and Nguyen, Duy MH and Tran, Chau H and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS'25}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS'25</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2025ais" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Mitigating Reward Over-optimization in Direct Alignment Algorithms with Adaptive Importance Sampling         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Phuc M Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Ngoc-Hieu Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Binh T Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2506.08681" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/AIS-Sampling4DAAs" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization (DPO) have emerged as alternatives to the standard Reinforcement Learning from Human Feedback (RLHF) for aligning large language models (LLMs) with human values. However, these methods are more susceptible to over-optimization, in which the model drifts away from the reference policy, leading to degraded performance as training progresses. This paper proposes a novel importance-sampling approach to mitigate the over-optimization problem of offline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective with an importance ratio that accounts for the reference policy distribution. IS-DAAs additionally avoid the high variance issue associated with importance sampling by clipping the importance ratio to a maximum value. Our extensive experiments demonstrate that IS-DAAs can effectively mitigate over-optimization, especially under low regularization strength, and achieve better performance than other methods designed to address this problem.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2025ais</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mitigating Reward Over-optimization in Direct Alignment Algorithms with Adaptive Importance Sampling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Phuc M and Nguyen, Ngoc-Hieu and Nguyen, Binh T and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2506.08681}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/AIS-Sampling4DAAs}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ICLR'25 -- COLM'25 (withdraw-missing title) -- NeurIPS'25}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ICLR'25 -- COLM'25 (withdraw-missing title) -- NeurIPS'25</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2025cad" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Unveiling Concept Attribution in Diffusion Models         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Phan Hoang</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2412.02542" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/CAD-attribution4diffusion" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion models have shown remarkable abilities in generating realistic and high-quality images from text prompts. However, a trained model remains black-box; little do we know about the role of its components in exhibiting a concept such as objects or styles. Recent works employ causal tracing to localize layers storing knowledge in generative models without showing how those layers contribute to the target concept. In this work, we approach the model interpretability problem from a more general perspective and pose a question: \textit{``How do model components work jointly to demonstrate knowledge?''}. We adapt component attribution to decompose diffusion models, unveiling how a component contributes to a concept. Our framework allows effective model editing, in particular, we can erase a concept from diffusion models by removing positive components while remaining knowledge of other concepts. Surprisingly, we also show there exist components that contribute negatively to a concept, which has not been discovered in the knowledge localization approach. Experimental results confirm the role of positive and negative components pinpointed by our framework, depicting a complete view of interpreting generative models. Our code is available at https://github.com/mail-research/CAD-attribution4diffusion</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2025cad</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unveiling Concept Attribution in Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Quang H and Hoang, Phan and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2412.02542}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/CAD-attribution4diffusion}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ICLR'25 -- CVPR'25 -- ICCV'25 -- NeurIPS'25}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ICLR'25 -- CVPR'25 -- ICCV'25 -- NeurIPS'25</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICML</abbr>
    
    </div>
  
  </div> -->

  <div id="shojaee2025llmsrbench" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICML</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
          <abbr class="badge" style="background-color: #04a96d;">ORAL</abbr>
        
        LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Parshin Shojaee,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Ngoc-Hieu Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Kazem Meidani,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Amir Barati Farimani,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Machine Learning</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2504.10415" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/deep-symbolic-mathematics/llm-srbench" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      <a href="https://huggingface.co/datasets/nnheui/llm-srbench" class="btn btn-sm z-depth-0" role="button" target="_blank">Data</a>
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shojaee2025llmsrbench</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shojaee, Parshin and Nguyen, Ngoc-Hieu and Meidani, Kazem and Farimani, Amir Barati and Doan, Khoa D and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{ORAL}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICML}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2504.10415}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/deep-symbolic-mathematics/llm-srbench}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://huggingface.co/datasets/nnheui/llm-srbench}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ICML'25}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ICML'25</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICLR</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024wicked" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICLR</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Ngoc-Hieu Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://the-anhta.github.io/" target="_blank">The-Anh Ta</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://thanhnguyentang.github.io/" target="_blank">Thanh Nguyen-Tang</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=xZU08d0AAAAJ&amp;hl=en" target="_blank">Hoang Thanh-Tung</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The Twelfth International Conference on Learning Representations</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/forum?id=1Z3C49JQVf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/wicked-oddities-backdoor" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep neural networks are vulnerable to backdoor attacks, a type of adversarial attack that poisons the training data to manipulate the behavior of models trained on such data. Clean-label attacks are a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data. Early works on clean-label attacks added triggers to a random subset of the training set, ignoring the fact that samples contribute unequally to the attack's success. This results in high poisoning rates and low attack success rates. To alleviate the problem, several supervised learning-based sample selection strategies have been proposed. However, these methods assume access to the entire labeled training set and require training, which is expensive and may not always be practical. This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g., in face recognition systems) and has no knowledge of the victim model or any other classes in the training set. We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting. Our threat model poses a serious threat in training machine learning models with third-party datasets, since the attack can be performed effectively with limited information. Experiments on benchmark datasets illustrate the effectiveness of our strategies in improving clean-label backdoor attacks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2024wicked</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Quang H and Nguyen, Ngoc-Hieu and Ta, The-Anh and Nguyen-Tang, Thanh and Wong, Kok-Seng and Thanh-Tung, Hoang and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICLR}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=1Z3C49JQVf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/wicked-oddities-backdoor}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS-W'23 -- ICML'24 -- NeurIPS'24 -- ICLR'25}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS-W'23 -- ICML'24 -- NeurIPS'24 -- ICLR'25</p>
    </div>
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2024&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">CODS-COMAD</abbr>
    
    </div>
  
  </div> -->

  <div id="khvatskii2024carol" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">CODS-COMAD</abbr>
            
          
          </span>
        
        
        
        Class-Aware Contrastive Optimization for Imbalanced Text Classification         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Grigorii Khvatskii,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Nuno Moniz,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  and Nitesh Chawla
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 8th International Conference on Data Science and Management of Data</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://khoadoan.me/coming-soon" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The unique characteristics of text data make classification tasks a complex problem. Advances in unsupervised and semi-supervised learning and autoencoder architectures addressed several challenges. However, they still struggle with imbalanced text classification tasks, a common scenario in real-world applications, demonstrating a tendency to produce embeddings with unfavorable properties, such as class overlap. In this paper, we show that leveraging class-aware contrastive optimization combined with denoising autoencoders can successfully tackle imbalanced text classification tasks, achieving better performance than the current state-of-the-art. Concretely, our proposal combines reconstruction loss with contrastive class separation in the embedding space, allowing a better balance between the truthfulness of the generated embeddings and the model's ability to separate different classes. Compared with an extensive set of traditional and state-of-the-art competing methods, our proposal demonstrates a notable increase in performance across a wide variety of text datasets.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">khvatskii2024carol</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Class-Aware Contrastive Optimization for Imbalanced Text Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Khvatskii, Grigorii and Moniz, Nuno and Doan, Khoa D and Chawla, Nitesh}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{8th International Conference on Data Science and Management of Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CODS-COMAD}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://khoadoan.me/coming-soon}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ARR-Oct'23 -- KDD'24 -- CODS-COMAD'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ARR-Oct'23 -- KDD'24 -- CODS-COMAD'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ECCV</abbr>
    
    </div>
  
  </div> -->

  <div id="pham2024SBL" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ECCV</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
          <abbr class="badge" style="background-color: #04a96d;">ORAL</abbr>
        
        Flatness-aware Sequential Learning Generates Resilient Backdoors         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Hoang V Pham</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://the-anhta.github.io/" target="_blank">The-Anh Ta</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    Anh Tran,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In European Conference on Computer Vision</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.arxiv.org/abs/2407.14738" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/SBL-resilient-backdoors" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="https://docs.google.com/presentation/d/1YEyQDSBardXdHCv-qBmxZnBwnXMAtRKZfWsawknowFs/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, backdoor attacks have become an emerging threat to the security of machine learning models. From the adversary's perspective, the implanted backdoors should be resistant to defensive algorithms, but some recently proposed fine-tuning defenses can remove these backdoors with notable efficacy. This is mainly due to the catastrophic forgetting (CF) property of deep neural networks. This paper counters CF of backdoors by leveraging continual learning (CL) techniques. We begin by investigating the connectivity between a backdoored and fine-tuned model in the loss landscape. Our analysis confirms that fine-tuning defenses, especially the more advanced ones, can easily push a poisoned model out of the backdoor regions, making it forget all about the backdoors. Based on this finding, we re-formulate backdoor training through the lens of CL and propose a novel framework, named Sequential Backdoor Learning (SBL), that can generate resilient backdoors. This framework separates the backdoor poisoning process into two tasks: the first task learns a backdoored model, while the second task, based on the CL principles, moves it to a backdoored region resistant to fine-tuning. We additionally propose to seek flatter backdoor regions via a sharpness-aware minimizer in the framework, further strengthening the durability of the implanted backdoor. Finally, we demonstrate the effectiveness of our method through extensive empirical experiments on several benchmark datasets in the backdoor domain. The source code is available at https://github.com/mail-research/SBL-resilient-backdoors</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pham2024SBL</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Flatness-aware Sequential Learning Generates Resilient Backdoors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Hoang V and Ta, The-Anh and Tran, Anh and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{ORAL}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/SBL-resilient-backdoors}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.arxiv.org/abs/2407.14738}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{https://docs.google.com/presentation/d/1YEyQDSBardXdHCv-qBmxZnBwnXMAtRKZfWsawknowFs/edit?usp=sharing}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{CVPR'24 -- ECCV'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>CVPR'24 -- ECCV'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ECCV</abbr>
    
    </div>
  
  </div> -->

  <div id="huynh2024quantizedbd" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ECCV</abbr>
            
          
          </span>
        
        
        
        Data Poisoning Quantization Backdoor Attack         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Tran Huynh,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    Anh Tran,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://scholar.google.com.au/citations?user=KcUuEKsAAAAJ&amp;hl=en" target="_blank">Tung Pham</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In European Conference on Computer Vision</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/11142.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep learning (DL) models are often large and require a lot of computing power. Hence, model quantization is frequently used to reduce their size and complexity, making them more suitable for deployment on edge devices or achieving real-time performance. It has been previously shown that standard quantization frameworks can be exploited to activate the backdoor in a DL model. This means that an attacker could create a hijacked model that appears normal and free from backdoors (even when examined by state-of-the-art defenses), but when it is quantized, the backdoor is activated, and the attacker can control the modelâ€™s output. Existing backdoor attack methods on quantization models require full access to the victim model, which might not hold in practice. In this work, we focus on designing a novel quantization backdoor based on data poisoning, which requires zero knowledge of the target model. The key component is a trigger pattern generator, which is trained together with a surrogate model in an alternating manner. The attackâ€™s effectiveness is tested on multiple benchmark datasets, including CIFAR10, CelebA, and ImageNet10, as well as state-of-the-art backdoor defenses.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huynh2024quantizedbd</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Data Poisoning Quantization Backdoor Attack}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huynh, Tran and Tran, Anh and Doan, Khoa D and Pham, Tung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ECCV}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/11142.pdf}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{CVPR'24 -- ECCV'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>CVPR'24 -- ECCV'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICPR</abbr>
    
    </div>
  
  </div> -->

  <div id="ghosh2024conceptbd" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICPR</abbr>
            
          
          </span>
        
        
        
        Composite Concept Extraction through Backdooring         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Banibrata Ghosh,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Haripriya Harikumar,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Svetha Venkatesh,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and Santu Rana
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 27th International Conference on Pattern Recognition</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2406.13411" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Learning composite concepts, such as "red car", from individual
examplesâ€”like a white car representing the concept of "car" and a red strawberry representing the concept of "red"â€”is inherently challenging. This paper introduces a novel method called Composite Concept Extractor (CoCE), which leverages techniques from traditional backdoor attacks to learn these composite concepts in a zero-shot setting, requiring
only examples of individual concepts. By repurposing the trigger-based model backdooring mechanism, we create a strategic distortion in the manifold of the target object (e.g., "car") induced by example objects with the target property (e.g., "red") from objects "red strawberry", ensuring the distortion selectively affects the target objects with the target property. Contrastive learning is then employed to further refine this distortion and a method is formulated for detecting objects that are influenced by the distortion. Extensive experiments with in-depth analysis across different datasets demonstrates the utility and applicability of our proposed approach.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ghosh2024conceptbd</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Composite Concept Extraction through Backdooring}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ghosh, Banibrata and Harikumar, Haripriya and Doan, Khoa D and Venkatesh, Svetha and Rana, Santu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{27th International Conference on Pattern Recognition}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICPR}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2406.13411}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{CVPR'24 -- ECCV'24 -- ICPR'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>CVPR'24 -- ECCV'24 -- ICPR'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024noncooperativeBAFL" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Tuan M Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Dung T Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2407.07917" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://anonymous.4open.science/r/nba-980F/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the promise of Federated Learning (FL) for privacy-preserving model training on distributed data, it remains susceptible to backdoor attacks. These attacks manipulate models by embedding triggers (specific input patterns) in the training data, forcing misclassification as predefined classes during deployment. Traditional single-trigger attacks and recent work on cooperative multiple-trigger attacks, where clients collaborate, highlight limitations in attack realism due to coordination requirements. We investigate a more alarming scenario: non-cooperative multiple-trigger attacks. Here, independent adversaries introduce distinct triggers targeting unique classes. These parallel attacks exploit FL's decentralized nature, making detection difficult. Our experiments demonstrate the alarming vulnerability of FL to such attacks, where individual backdoors can be successfully learned without impacting the main task. This research emphasizes the critical need for robust defenses against diverse backdoor attacks in the evolving FL landscape. While our focus is on empirical analysis, we believe it can guide backdoor research toward more realistic settings, highlighting the crucial role of FL in building robust defenses against diverse backdoor threats. The code is available at https://anonymous.4open.science/r/nba-980F/.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2024noncooperativeBAFL</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Tuan M and Nguyen, Dung T and Doan, Khoa D and Wong, Kok-Seng}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.07917}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://anonymous.4open.science/r/nba-980F/}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024metallm" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Cao-Duy Hoang</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Juliette Decugis,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://niteshchawla.nd.edu/" target="_blank">Nitesh V Chawla</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2407.10834" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/MetaLLM-wrapper/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The rapid progress in machine learning (ML) has brought forth many large language models (LLMs) that excel in various tasks and areas. These LLMs come with different abilities and costs in terms of computation or pricing. Since the demand for each query can vary, e.g., because of the queried domain or its complexity, defaulting to one LLM in an application is not usually the best choice, whether it is the biggest, priciest, or even the one with the best average test performance. Consequently, picking the right LLM that is both accurate and cost-effective for an application remains a challenge. In this paper, we introduce MetaLLM, a framework that dynamically and intelligently routes each query to the optimal LLM (among several available LLMs) for classification tasks, achieving significantly improved accuracy and cost-effectiveness. By framing the selection problem as a multi-armed bandit, MetaLLM balances prediction accuracy and cost efficiency under uncertainty. Our experiments, conducted on popular LLM platforms such as OpenAI's GPT models, Amazon's Titan, Anthropic's Claude, and Meta's LLaMa, showcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for future extensions beyond classification tasks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2024metallm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Quang H and Hoang, Cao-Duy and Decugis, Juliette and Manchanda, Saurav and Chawla, Nitesh V and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.10834}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/MetaLLM-wrapper/}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="yang2023synthesizing" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Sze Jue Yang</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Chinh D La</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.cs.cornell.edu/~eugene/" target="_blank">Eugene Bagdasaryan</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&amp;hl=en" target="_blank">Anh T Tran</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://cs-chan.com/" target="_blank">Chee Seng Chan</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2312.03419" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/synthetic-physical-backdoor-datasets" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Backdoor attacks, representing an emerging threat to the integrity of deep neural networks, have garnered significant attention due to their ability to compromise deep learning systems clandestinely. While numerous backdoor attacks occur within the digital realm, their practical implementation in real-world prediction systems remains limited and vulnerable to disturbances in the physical world. Consequently, this limitation has given rise to the development of physical backdoor attacks, where trigger objects manifest as physical entities within the real world. However, creating the requisite dataset to train or evaluate a physical backdoor model is a daunting task, limiting the backdoor researchers and practitioners from studying such physical attack scenarios. This paper unleashes a recipe that empowers backdoor researchers to effortlessly create a malicious, physical backdoor dataset based on advances in generative modeling. Particularly, this recipe involves 3 automatic modules: suggesting the suitable physical triggers, generating the poisoned candidate samples (either by synthesizing new samples or editing existing clean samples), and finally refining for the most plausible ones. As such, it effectively mitigates the perceived complexity associated with creating a physical backdoor dataset, transforming it from a daunting task into an attainable objective. Extensive experiment results show that datasets created by our â€œrecipeâ€ enable adversaries to achieve an impressive attack success rate on real physical world data and exhibit similar properties compared to previous physical backdoor attack studies. This paper offers researchers a valuable toolkit for studies of physical backdoors, all within the confines of</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yang2023synthesizing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Sze Jue and La, Chinh D and Nguyen, Quang H and Bagdasaryan, Eugene and Wong, Kok-Seng and Tran, Anh T and Chan, Chee Seng and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/synthetic-physical-backdoor-datasets}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2312.03419}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="huynh2023fmn" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        
        Forget-Me-Not: Making Backdoor Hard to be Forgotten in Fine-tuning         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Tran Ngoc Huynh,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&amp;hl=en" target="_blank">Anh T Tran</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://scholar.google.com.au/citations?user=KcUuEKsAAAAJ&amp;hl=en" target="_blank">Tung Pham</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/forum?id=T23HYw6lta" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">huynh2023fmn</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Forget-Me-Not: Making Backdoor Hard to be Forgotten in Fine-tuning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huynh, Tran Ngoc and Tran, Anh T and Doan, Khoa D and Pham, Tung}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=T23HYw6lta}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ACL-Findings</abbr>
    
    </div>
  
  </div> -->

  <div id="hoang2023advfooler" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ACL-Findings</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Fooling the Textual Fooler via Randomizing Latent Representations         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Cao-Duy Hoang</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://v-mipeng.github.io/" target="_blank">Minlong Peng</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Findings of the Association for Computational Linguistics</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2310.01452" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/AdvFooler-text-defender" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite outstanding performance in a variety of NLP tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Among these attacks, adversarial word-level perturbations are well-studied and effective attack strategies. Since these attacks work in black-box settings, they do not require access to the model architecture or model parameters and thus can be detrimental to existing NLP applications. To perform an attack, the adversary queries the victim model many times to determine the most important words in an input text and to replace these words with their corresponding synonyms. In this work, we propose a lightweight and attack-agnostic defense whose main goal is to perplex the process of generating an adversarial example in these query-based black-box attacks; that is to fool the textual fooler. This defense, named AdvFooler, works by randomizing the latent representation of the input at inference time. Different from existing defenses, AdvFooler does not necessitate additional computational overhead during training nor relies on assumptions about the potential adversarial perturbation set while having a negligible impact on the model's accuracy. Our theoretical and empirical analyses highlight the significance of robustness resulting from confusing the adversary via randomizing the latent space, as well as the impact of randomization on clean accuracy. Finally, we empirically demonstrate near state-of-the-art robustness of AdvFooler against representative adversarial word-level attacks on two benchmark datasets.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hoang2023advfooler</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fooling the Textual Fooler via Randomizing Latent Representations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Cao-Duy and Nguyen, Quang H and Manchanda, Saurav and Peng, Minlong and Wong, Kok-Seng and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ACL-Findings}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2310.01452}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/AdvFooler-text-defender}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{EMNLP'24 -- ICLR'24 -- ACL'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>EMNLP'24 -- ICLR'24 -- ACL'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="yang2023lossybackdoors" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Sze Jue Yang</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://cs-chan.com/" target="_blank">Chee Seng Chan</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2308.16684</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2308.16684" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yang2023lossybackdoors</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yang, Sze Jue and Nguyen, Quang H and Chan, Chee Seng and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2308.16684}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2308.16684}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PREPRINT</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2022coophash" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge" style="background-color: black;">PREPRINT</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        CoopHash: Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=glaTwrUAAAAJ&amp;hl=en" target="_blank">Jianwen Xie</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Yaxuan Zhu,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=9zmGBugAAAAJ&amp;hl=en" target="_blank">Yang Zhao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/abs/2210.04288" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Leveraging supervised information can lead to superior retrieval performance in the image hashing domain but the performance degrades significantly without enough labeled data. One effective solution to boost the performance is to employ generative models, such as Generative Adversarial Networks (GANs), to generate synthetic data in an image hashing model. However, GAN-based methods are difficult to train and suffer from mode collapse issue, which prevents the hashing approaches from jointly training the generative models and the hash functions. This limitation results in sub-optimal retrieval performance. To overcome this limitation, we propose a novel framework, the generative cooperative hashing network (CoopHash), which is based on the energy-based cooperative learning. CoopHash jointly learns a powerful generative representation of the data and a robust hash function. CoopHash has two components: a top-down contrastive pair generator that synthesizes contrastive images and a bottom-up multipurpose descriptor that simultaneously represents the images from multiple perspectives, including probability density, hash code, latent code, and category. The two components are jointly learned via a novel likelihood-based cooperative learning scheme. We conduct experiments on several real-world datasets and show that the proposed method outperforms the competing hashing supervised methods, achieving up to 10% relative improvement over the current state-of-the-art supervised hashing methods, and exhibits a significantly better performance in out-of-distribution retrieval.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doan2022coophash</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CoopHash: Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Xie, Jianwen and Zhu, Yaxuan and Zhao, Yang and Li, Ping}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PREPRINT}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2210.04288}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICLR</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2023randomized" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICLR</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://ylao.people.clemson.edu/" target="_blank">Yingjie Lao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com.au/citations?user=KcUuEKsAAAAJ&amp;hl=en" target="_blank">Tung Pham</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The Twelfth International Conference on Learning Representations</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/forum?id=vZ6r9GMT1n" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/mail-research/randomized_defenses" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent works have shown that deep neural networks are vulnerable to adversarial examples that find samples close to the original image but can make the model misclassify. Even with access only to the model's output, an attacker can employ black-box attacks to generate such adversarial examples. In this work, we propose a simple and lightweight defense against black-box attacks by adding random noise to hidden features at intermediate layers of the model at inference time. Our theoretical analysis confirms that this method effectively enhances the model's resilience against both score-based and decision-based black-box attacks. Importantly, our defense does not necessitate adversarial training and has minimal impact on accuracy, rendering it applicable to any pre-trained model. Our analysis also reveals the significance of selectively adding noise to different parts of the model based on the gradient of the adversarial objective function, which can be varied during the attack. We demonstrate the robustness of our defense against multiple black-box attacks through extensive empirical experiments involving diverse models with various architectures.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2023randomized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Quang H and Lao, Yingjie and Pham, Tung and Wong, Kok-Seng and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICLR}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=vZ6r9GMT1n}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/mail-research/randomized_defenses}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS'23 -- ICLR'24}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS'23 -- ICLR'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024iba" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Iba: Towards irreversible backdoor attacks in federated learning         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Thuy Dung Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Tuan M Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&amp;hl=en" target="_blank">Anh T Tran</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Advances in Neural Information Processing Systems</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/sail-research/iba" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Federated learning (FL) is a distributed learning approach that enables machine learning models to be trained on decentralized data without compromising end devices' personal, potentially sensitive data. However, the distributed nature and uninvestigated data intuitively introduce new security vulnerabilities, including backdoor attacks. In this scenario, an adversary implants backdoor functionality into the global model during training, which can be activated to cause the desired misbehaviors for any input with a specific adversarial pattern. Despite having remarkable success in triggering and distorting model behavior, prior backdoor attacks in FL often hold impractical assumptions, limited imperceptibility, and durability. Specifically, the adversary needs to control a sufficiently large fraction of clients or know the data distribution of other honest clients. In many cases, the trigger inserted is often visually apparent, and the backdoor effect is quickly diluted if the adversary is removed from the training process. To address these limitations, we propose a novel backdoor attack framework in FL, the Irreversible Backdoor Attack (IBA), that jointly learns the optimal and visually stealthy trigger and then gradually implants the backdoor into a global model. This approach allows the adversary to execute a backdoor attack that can evade both human and machine inspections. Additionally, we enhance the efficiency and durability of the proposed attack by selectively poisoning the model's parameters that are least likely updated by the main task's learning process and constraining the poisoned model update to the vicinity of the global model. Finally, we evaluate the proposed attack framework on several benchmark datasets, including MNIST, CIFAR-10, and Tiny ImageNet, and achieved high success rates while simultaneously bypassing existing backdoor defenses and achieving a more durable backdoor effect compared to other backdoor attacks. Overall, IBA offers a more effective, stealthy, and durable approach to backdoor attacks in FL.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2024iba</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Iba: Towards irreversible backdoor attacks in federated learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Thuy Dung and Nguyen, Tuan M and Tran, Anh T and Doan, Khoa D and Wong, Kok-Seng}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS'23}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/sail-research/iba}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS'23</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">EAAI</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024backdoor" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">EAAI</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Thuy Dung Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Tuan M Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Phi Le Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    Hieu H Pham,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Engineering Applications of Artificial Intelligence</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://www.sciencedirect.com/science/article/pii/S0952197623013507" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Federated learning (FL) is an approach within the realm of machine learning (ML) that allows the use of distributed data without compromising personal privacy. In FL, it becomes evident that the training data among participants frequently exhibit heterogeneous distribution characteristics. This inherent heterogeneity poses a substantial challenge for the orchestration server as it strives to assess the reliability of each local model update. Due to this challenge, FL becomes susceptible to various potential risks, with the ominous backdoor attack standing out as one of the most menacing threats. Backdoor attacks involve the insertion of malicious functionality into a targeted model through poisoned updates from malicious clients. These attacks can cause the global model to misbehave on specific inputs while appearing normal in other instances. Although the backdoor attacks received significant attention for their potential impact on practical deep learning applications, their exploration within the realm of FL remains limited. This survey seeks to address this gap by offering an all-encompassing examination of prevailing backdoor attack tactics and defenses in the context of FL. We include an exhaustive analysis of diverse approaches to provide a comprehensive understanding of this intricate landscape. Furthermore, we also discuss the challenges and potential future directions for attacks and defenses in the context of FL.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2024backdoor</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Thuy Dung and Nguyen, Tuan M and Le Nguyen, Phi and Pham, Hieu H and Doan, Khoa D and Wong, Kok-Seng}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Engineering Applications of Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{127}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107166}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{EAAI'24}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{EAAI}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0952197623013507}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>EAAI'24</p>
    </div>
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2023&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">UAI</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2024cold" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">UAI</abbr>
            
          
          </span>
        
        
        
        Cold-start Recommendation by Personalized Embedding Region Elicitation         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://hieunt91.github.io/" target="_blank">Hieu Trung Nguyen</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://duykhuongnguyen.github.io/" target="_blank">Duy Nguyen</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
                
                
          
          
            
              
                
                  and <a href="https://vietanhnguyen.net/" target="_blank">Viet Anh Nguyen</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The Conference on Uncertainty in Artificial Intelligence</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2406.00973" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Rating elicitation is a success element for recommender systems to perform well at cold-starting, in which the systems need to recommend items to a newly arrived user with no prior knowledge about the user's preference. Existing elicitation methods employ a fixed set of items to learn the user's preference and then infer the users' preferences on the remaining items. Using a fixed seed set can limit the performance of the recommendation system since the seed set is unlikely optimal for all new users with potentially diverse preferences. This paper addresses this challenge using a 2-phase, personalized elicitation scheme. First, the elicitation scheme asks users to rate a small set of popular items in a ``burn-in'' phase. Second, it sequentially asks the user to rate adaptive items to refine the preference and the user's representation. Throughout the process, the system represents the user's embedding value not by a point estimate but by a region estimate. The value of information obtained by asking the user's rating on an item is quantified by the distance from the region center embedding space that contains with high confidence the true embedding value of the user. Finally, the recommendations are successively generated by considering the preference region of the user. We show that each subproblem in the elicitation scheme can be efficiently implemented. Further, we empirically demonstrate the effectiveness of the proposed method against existing rating-elicitation methods on several prominent datasets.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2024cold</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cold-start Recommendation by Personalized Embedding Region Elicitation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Hieu Trung and Nguyen, Duy and Doan, Khoa D and Nguyen, Viet Anh}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Conference on Uncertainty in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{UAI}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2406.00973}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{RecSys'23 -- CIKM'23 -- AAAI'24 -- UAI'24}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>RecSys'23 -- CIKM'23 -- AAAI'24 -- UAI'24</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS-W</abbr>
    
    </div>
  
  </div> -->

  <div id="hung2023clean" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS-W</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Clean-label Backdoor Attacks by Selectively Poisoning with Limited Information from Target Class         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Ngoc-Hieu Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://the-anhta.github.io/" target="_blank">The-Anh Ta</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://thanhnguyentang.github.io/" target="_blank">Thanh T Nguyen</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=xZU08d0AAAAJ&amp;hl=en" target="_blank">Thanh-Tung Hoang</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                and <u>Khoa D Doan</u>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS 2023 Workshop on Backdoors in Deep Learning-The Good, the Bad, and the Ugly</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/forum?id=JvUuutHa2s&amp;noteId=dtKPNhZu9V" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hung2023clean</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clean-label Backdoor Attacks by Selectively Poisoning with Limited Information from Target Class}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Quang H and Nguyen, Ngoc-Hieu and Ta, The-Anh and Nguyen, Thanh T and Hoang, Thanh-Tung and Doan, Khoa D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS 2023 Workshop on Backdoors in Deep Learning-The Good, the Bad, and the Ugly}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS-W}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=JvUuutHa2s&amp;noteId=dtKPNhZu9V}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ACML</abbr>
    
    </div>
  
  </div> -->

  <div id="nguyen2023empirical" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ACML</abbr>
            
          
          </span>
        
        
        
        Empirical Study of Federated Unlearning: Efficiency and Effectiveness         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Thai-Hung Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Hong-Phuc Vu,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Dung Thuy Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    Tuan Minh Nguyen,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://sail-research.com/" target="_blank">Kok-Seng Wong</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Asian Conference on Machine Learning</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://proceedings.mlr.press/v222/nguyen24a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The right to be forgotten (RTBF) is a concept that pertains to an individualâ€™s right to request the removal or deletion of their personal information when it is no longer necessary, relevant, or accurate for the purposes for which it was initially collected. Machine Learning (ML) models often rely on large, diverse datasets for optimal performance. Hence, when an individual exercises the RTBF, it can impact the ML modelâ€™s performance and accuracy. In the context of Federated Learning (FL), where a server trains a model across multiple decentralized devices without moving data away from clients, implementing the RTBF in FL presents some unique challenges compared to traditional ML approaches. For instance, the decentralized nature makes it challenging to identify and remove specific user data from the model. Although various unlearning methods have been proposed in the literature, they have not been well investigated from the efficiency perspective. To fill this gap, this paper presents an empirical study to investigate the impacts of various unlearning methods. Our experiments are designed in diverse scenarios involving multiple communication and unlearning rounds using three datasets, MNIST, CIFAR-10, and CIFAR-100. We utilize backdoor attack and Cosine Similarity to assess the effectiveness of each unlearning method. The findings and insights from this research can be integrated into FL systems to enhance their overall performance and effectiveness. Our research codes are available on GitHub at\url {https://github. com/sail-research/fed-unlearn}.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2023empirical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Empirical Study of Federated Unlearning: Efficiency and Effectiveness}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Thai-Hung and Vu, Hong-Phuc and Nguyen, Dung Thuy and Nguyen, Tuan Minh and Doan, Khoa D and Wong, Kok-Seng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Asian Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{959--974}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ACML'23}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ACML}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v222/nguyen24a.html}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ACML'23</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">SIGIR</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2023flora" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">SIGIR</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Asymmetric Hashing for Fast Ranking via Neural Network Measures         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://www.stat.ucla.edu/~jxie/" target="_blank">Shulong Tan</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.cs.rit.edu/~wjz/" target="_blank">Weijie Zhao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/abs/10.1145/3539618.3591640" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Fast item ranking is an important task in recommender systems. In previous works, graph-based Approximate Nearest Neighbor (ANN) approaches have demonstrated good performance on item ranking tasks with generic searching/matching measures (including complex measures such as neural network measures). However, since these ANN approaches must go through the neural measures several times during ranking, the computation is not practical if the neural measure is a large network. On the other hand, fast item ranking using existing hashing-based approaches, such as Locality Sensitive Hashing (LSH), only works with a limited set of measures, such as cosine and Euclidean distance, but not with general search measures such as neural networks. Given an arbitrary searching measure, previous learning-to-hash approaches are also not suitable to solve the fast item ranking problem since they can take a significant amount of time and computation to train the hash functions to approximate the searching measure due to a large number of possible training pairs in this problem. Hashing approaches, however, are attractive because they provide a principal and efficient way to retrieve candidate items. In this paper, we propose a simple and effective learning-to-hash approach for the fast item ranking problem that can be used to efficiently approximate any type of measure, including neural network measures. Specifically, we solve this problem with an asymmetric hashing framework based on discrete inner product fitting. We learn a pair of related hash functions that map heterogeneous objects (e.g., users and items) into a common discrete space where the inner product of their binary codes reveals their true similarity defined via the original searching measure. The fast ranking problem is reduced to an ANN search via this asymmetric hashing scheme. Then, we propose a sampling strategy to efficiently select relevant and contrastive samples to train the hashing model. We empirically validate the proposed method against the existing state-of-the-art fast item ranking methods in several combinations of non-linear searching functions and prominent datasets.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2023flora</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{SIGIR}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymmetric Hashing for Fast Ranking via Neural Network Measures}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Tan, Shulong and Zhao, Weijie and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{46th International ACM SIGIR Conference on Research and Development in Information Retrieval}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{SIGIR'21 -- RecSys'21 -- WSDM'22 -- WWW'22 -- SIGIR'22 -- VLDB'23 -- CIKM'22 -- WWW'23 -- SIGIR'23}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3539618.3591640}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>SIGIR'21 -- RecSys'21 -- WSDM'22 -- WWW'22 -- SIGIR'22 -- VLDB'23 -- CIKM'22 -- WWW'23 -- SIGIR'23</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICML-W</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2023bdvits" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICML-W</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        A Cosine Similarity-based Method for Out-of-Distribution Detection         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Ngoc-Hieu Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
            
              
            
              
            
              
            
          
          
            
              
                
                  
                    <span style="font-weight: bold;">Quang H Nguyen</span>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://thanhnguyentang.github.io/" target="_blank">Thanh T Nguyen</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://scholar.google.com/citations?user=xZU08d0AAAAJ&amp;hl=en" target="_blank">Thanh-Tung Hoang</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICML 2023 Workshop on Spurious Correlations, Invariance, and Stability</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2306.14920.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The ability to detect OOD data is a crucial aspect of practical machine learning applications. In this work, we show that cosine similarity between the test feature and the typical ID feature is a good indicator of OOD data. We propose Class Typical Matching (CTM), a post hoc OOD detection algorithm that uses a cosine similarity scoring function. Extensive experiments on multiple benchmarks show that CTM outperforms existing post hoc OOD detection methods.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2023bdvits</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICML-W}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Cosine Similarity-based Method for Out-of-Distribution Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Ngoc-Hieu and Nguyen, Quang H and Nguyen, Thanh T and Doan, Khoa D and Hoang, Thanh-Tung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICML 2023 Workshop on Spurious Correlations, Invariance, and Stability}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2306.14920.pdf}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{none.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">AAAI</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2023bdvitt" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">AAAI</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Defending backdoor attacks on vision transformer via patch processing         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://ylao.people.clemson.edu/" target="_blank">Yingjie Lao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In AAAI Conference on Artificial Intelligence</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25125" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Vision Transformers (ViTs) have a radically different architecture with significantly less inductive bias than Convolutional Neural Networks. Along with the improvement in performance, security and robustness of ViTs are also of great importance to study. In contrast to many recent works that exploit the robustness of ViTs against adversarial examples, this paper investigates a representative causative attack, ie, backdoor. We first examine the vulnerability of ViTs against various backdoor attacks and find that ViTs are also quite vulnerable to existing attacks. However, we observe that the clean-data accuracy and backdoor attack success rate of ViTs respond distinctively to patch transformations before the positional encoding. Then, based on this finding, we propose an effective method for ViTs to defend both patch-based and blending-based trigger backdoor attacks via patch processing. The performances are evaluated on several benchmark datasets, including CIFAR10, GTSRB, and TinyImageNet, which show the proposedds defense is very successful in mitigating backdoor attacks for ViTs. To the best of our knowledge, this paper presents the first defensive strategy that utilizes a unique characteristic of ViTs against backdoor attacks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2023bdvitt</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AAAI}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Defending backdoor attacks on vision transformer via patch processing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Lao, Yingjie and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{CVPR'22 -- ICCV'22 -- AAAI'23}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2023bdvits.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/25125}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>CVPR'22 -- ICCV'22 -- AAAI'23</p>
    </div>
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2022&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ACCV</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2022genhash" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ACCV</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Unified Learning of Multipurpose Energy Based Generative Hashing Network         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Sixteenth Asian Conference on Computer Vision</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Hashing methods often face critical efficiency challenges, such as generalization with limited labeled data, and robustness issues (such as changes in the data distribution and missing information in the input data) in real-world retrieval applications. However, it is non-trivial to learn a hash function in existing supervised hashing methods with both acceptable efficiency and robustness. In this paper, we explore a unified generative hashing model based on an explicit energy-based model (EBM) that exhibits a better generalization with limited labeled data, and better robustness against distributional changes and missing data. Unlike the previous implicit generative adversarial network (GAN) based hashing approaches, which suffer from several practical difficulties since they simultaneously train two networks (the generator and the discriminator), our approach only trains one single generative network with multiple objectives. Specifically, the proposed generative hashing model is a bottom-up multipurpose network that simultaneously represents the images from multiple perspectives, including explicit probability density, binary hash code, and category. Our model is easier to train than GAN-based approaches as it is based on finding the maximum likelihood of the density function. The proposed model also exhibits significant robustness toward out-of-distribution query data and is able to overcome missing data in both the training and testing phase with minimal retrieval performance degradation. Extensive experiments on several real-world datasets demonstrate superior results in which the proposed model achieves up to 5% improvement over the current state-of-the-art supervised hashing methods and exhibits a significant performance boost and robustness in both out-of-distribution retrieval and missing data scenarios.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2022genhash</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unified Learning of Multipurpose Energy Based Generative Hashing Network}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Sixteenth Asian Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ACCV}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{TPAMI'21 -- ACCV'22}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{false}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>TPAMI'21 -- ACCV'22</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2022marksman" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://ylao.people.clemson.edu/" target="_blank">Yingjie Lao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Thirty-Sixth Conference on Neural Information Processing Systems</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/forum?id=i-k6J4VkCDq" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/khoadoan106/backdoor_attacks" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="https://nips.cc/media/neurips-2022/Slides/52924.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In recent years, machine learning models have been shown to be vulnerable to backdoor attacks. Under such attacks, an adversary embeds a stealthy backdoor into the trained model such that the compromised models will behave normally on clean inputs but will misclassify according to the adversary's control on maliciously constructed input with a trigger. While these existing attacks are very effective, the adversary's capability is limited: given an input, these attacks can only cause the model to misclassify toward a single pre-defined or target class. In contrast, this paper exploits a novel backdoor attack with a much more powerful payload, denoted as Marksman, where the adversary can arbitrarily choose which target class the model will misclassify given any input during inference. To achieve this goal, we propose to represent the trigger function as a class-conditional generative model and to inject the backdoor in a constrained optimization framework, where the trigger function learns to generate an optimal trigger pattern to attack any target class at will while simultaneously embedding this generative backdoor into the trained model. Given the learned trigger-generation function, during inference, the adversary can specify an arbitrary backdoor attack target class, and an appropriate trigger causing the model to classify toward this target class is created accordingly. We show empirically that the proposed framework achieves high attack performance (e.g., 100% attack success rates in several experiments) while preserving the clean-data performance in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and TinyImageNet. The proposed Marksman backdoor attack can also easily bypass existing backdoor defenses that were originally designed against backdoor attacks with a single target class. Our work takes another significant step toward understanding the extensive risks of backdoor attacks in practice.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2022marksman</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Lao, Yingjie and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-Sixth Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS'22}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2022marksman.png}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=i-k6J4VkCDq}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan106/backdoor_attacks}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{https://nips.cc/media/neurips-2022/Slides/52924.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS'22</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">CVPR</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2022hswd" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">CVPR</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://sites.google.com/site/pengyangshomepage/" target="_blank">Peng Yang</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Conference on Computer Vision and Pattern Recognition</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/pdf?id=uaqweIZ-9_k" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/khoadoan106/single_loss_quantization" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="/assets/pdf/doan2022hswd-slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Image hashing is a principled approximate nearest neighbor approach to find similar items to a query in a large collection of images. Hashing aims to learn a binary-output function that maps an image to a binary vector. For optimal retrieval performance, producing balanced hash codes with low-quantization error to bridge the gap between the learning stage's continuous relaxation and the inference stage's discrete quantization is important. However, in the existing deep supervised hashing methods, coding balance and low-quantization error are difficult to achieve and involve several losses. We argue that this is because the existing quantization approaches in these methods are heuristically constructed and not effective to achieve these objectives. This paper considers an alternative approach to learning the quantization constraints. The task of learning balanced codes with low quantization error is re-formulated as matching the learned distribution of the continuous codes to a pre-defined discrete, uniform distribution. This is equivalent to minimizing the distance between two distributions. We then propose a computationally efficient distributional distance by leveraging the discrete property of the hash functions. This distributional distance is a valid distance and enjoys lower time and sample complexities. The proposed single-loss quantization objective can be integrated into any existing supervised hashing method to improve code balance and quantization error. Experiments confirm that the proposed approach substantially improves the performance of several representative hashing methods.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2022hswd</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Yang, Peng and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{CVPR'22}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{doan2022hswd-slides.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan106/single_loss_quantization}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/pdf?id=uaqweIZ-9_k}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2022hswd.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>CVPR'22</p>
    </div>
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2021&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">NeurIPS</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2021wb" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">NeurIPS</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Backdoor Attack with Imperceptible Input and Latent Modification         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://ylao.people.clemson.edu/" target="_blank">Yingjie Lao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Thirty-Fifth Conference on Neural Information Processing Systems</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      <a href="https://recorder-v3.slideslive.com/?share=51522&amp;s=8af881c0-56e8-451e-865f-adb1e90e5471" class="btn btn-sm z-depth-0" role="button" target="_blank">VIDEO</a>
    
    
    
    
      <a href="https://github.com/khoadoan106/backdoor_attacks" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="/assets/pdf/doan2021wb-slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent studies have shown that deep neural networks (DNN) are vulnerable to various adversarial attacks. In particular, an adversary can inject a stealthy backdoor into a model such that the compromised model will behave normally without the presence of the trigger. Techniques for generating backdoor images that are visually imperceptible from clean images have also been developed recently, which further enhance the stealthiness of the backdoor attacks from the input space. Along with the development of attacks, defense against backdoor attacks is also evolving. Many existing countermeasures found that backdoor tends to leave tangible footprints in the latent or feature space, which can be utilized to mitigate backdoor attacks.In this paper, we extend the concept of imperceptible backdoor from the input space to the latent representation, which significantly improves the effectiveness against the existing defense mechanisms, especially those relying on the distinguishability between clean inputs and backdoor inputs in latent space. In the proposed framework, the trigger function will learn to manipulate the input by injecting imperceptible input noise while matching the latent representations of the clean and manipulated inputs via a Wasserstein-based regularization of the corresponding empirical distributions. We formulate such an objective as a non-convex and constrained optimization problem and solve the problem with an efficient stochastic alternating optimization procedure. We name the proposed backdoor attack as Wasserstein Backdoor (WB), which achieves a high attack success rate while being stealthy from both the input and latent spaces, as tested in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and TinyImagenet.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2021wb</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Backdoor Attack with Imperceptible Input and Latent Modification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Lao, Yingjie and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-Fifth Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{NeurIPS'21}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan106/backdoor_attacks}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://recorder-v3.slideslive.com/?share=51522&amp;s=8af881c0-56e8-451e-865f-adb1e90e5471}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{doan2021wb-slides.pdf}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2021wb.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>NeurIPS'21</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">ICCV</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2021lira" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">ICCV</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        LIRA: Learnable, Imperceptible and Robust Backdoor Attacks         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://ylao.people.clemson.edu/" target="_blank">Yingjie Lao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.cs.rit.edu/~wjz/" target="_blank">Weijie Zhao</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://research.baidu.com/People/index-view?id=111" target="_blank">Ping Li</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Conference on Computer Vision</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/khoadoan106/backdoor_attacks" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
      
      <a href="https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, machine learning models have demonstrated to be vulnerable to backdoor attacks, primarily due to the lack of transparency in black-box models such as deep neural networks. A third-party model can be poisoned such that it works adequately in normal conditions but behaves maliciously on samples with specific trigger patterns. However, the trigger injection function is manually defined in most existing backdoor attack methods, e.g., placing a small patch of pixels on an image or slightly deforming the image before poisoning the model. This results in a two-stage approach with a sub-optimal attack success rate and a lack of complete stealthiness under human inspection.

  In this paper, we propose a novel and stealthy backdoor attack framework, LIRA, which jointly learns the optimal, stealthy trigger injection function and poisons the model. We formulate such an objective as a non-convex, constrained optimization problem. Under this optimization framework, the trigger generator function will learn to manipulate the input with imperceptible noise to preserve the model performance on the clean data and maximize the attack success rate on the poisoned data. Then, we solve this challenging optimization problem with an efficient, two-stage stochastic optimization procedure. Finally, the proposed attack framework achieves 100% success rates in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and T-ImageNet, while simultaneously bypassing existing backdoor defense methods and human inspection.
  </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2021lira</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{ICCV}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LIRA: Learnable, Imperceptible and Robust Backdoor Attacks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Lao, Yingjie and Zhao, Weijie and Li, Ping}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{ICCV'21}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan106/backdoor_attacks}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Slides.pdf}</span><span class="p">,</span>
  <span class="na">poster</span> <span class="p">=</span> <span class="s">{https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Poster.pdf}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2021lira.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>ICCV'21</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">SIGIR</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2021interpretable" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">SIGIR</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Suchismit Mahapatra,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/doan2021interpretable.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      <a href="https://www.youtube.com/watch?v=IWxxsuFPsgs&amp;t=1s" class="btn btn-sm z-depth-0" role="button" target="_blank">VIDEO</a>
    
    
    
    
      <a href="https://github.com/khoadoan/GraphOTSim" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="https://github.com/khoadoan/GraphOTSim/raw/main/resources/SIGIR21-fp0937-slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
        
    
    
      <a class="submissions btn btn-sm z-depth-0" role="button">Submission History</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Computing graph similarity is an important task in many graph-related applications
  such as retrieval in graph databases or graph clustering. While numerous measures
  have been proposed to capture the similarity between a pair of graphs, Graph Edit
  Distance (GED) and Maximum Common Subgraphs (MCS) are the two widely used measures
  in practice. GED and MCS are domain-agnostic measures of structural similarity between
  the graphs and define the similarity as a function of pairwise alignment of different
  entities (such as nodes, edges, and subgraphs) in the two graphs. The explicit explainability
  offered by the pairwise alignment provides transparency and justification of the similarity
  score, thus, GED and MCS have important practical applications. However, their exact
  computations are known to be NP-hard. While recently proposed neural-network based
  approximations have been shown to accurately compute these similarity scores, they
  have limited ability in providing comprehensive explanations compared to classical
  combinatorial algorithms, e.g., Beam search. This paper aims at efficiently approximating
  these domain-agnostic similarity measures through a neural network, and simultaneously
  learning the alignments (i.e., explanations) similar to those of classical intractable
  methods. Specifically, we formulate the similarity between a pair of graphs as the
  minimal "transformation" cost from one graph to another in the learnable node-embedding
  space. We show that, if node embedding is able to capture its neighborhood context
  closely, our proposed similarity function closely approximates both the alignment
  and the similarity score of classical methods. Furthermore, we also propose an efficient
  differentiable computation of our proposed objective for model training. Empirically,
  we demonstrate that the proposed method achieves up to 50%-100% reduction in the Mean
  Squared Error for the graph similarity approximation task and up to 20% improvement
  in the retrieval evaluation metrics for the graph retrieval task. The source code
  is available at https://github.com/khoadoan/GraphOTSim.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2021interpretable</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{SIGIR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3404835.3462960}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan/GraphOTSim}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{doan2021interpretable.pdf}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{https://github.com/khoadoan/GraphOTSim/raw/main/resources/SIGIR21-fp0937-slides.pdf}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=IWxxsuFPsgs&amp;t=1s}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2021interpretable.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">submissions</span> <span class="p">=</span> <span class="s">{AAAI'21 -- WWW'21 -- SIGIR'21}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Manchanda, Saurav and Mahapatra, Suchismit and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450380379}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3404835.3462960}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{44th International ACM SIGIR Conference on Research and Development in Information Retrieval}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{665â€“674}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{similarity search, model interpretability, graph similarity, GCN}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Virtual Event, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{SIGIR '21}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="submissions hidden">
      <p>AAAI'21 -- WWW'21 -- SIGIR'21</p>
    </div>
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2020&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">WWW</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2020efficient" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">WWW</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Efficient Implicit Unsupervised Text Hashing Using Adversarial Autoencoder         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of The Web Conference</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://dl.acm.org/doi/abs/10.1145/3366423.3380150" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://people.cs.vt.edu/~reddy/papers/WWW20a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Searching for documents with semantically similar content is a fundamental problem
  in the information retrieval domain with various challenges, primarily, in terms of
  efficiency and effectiveness. Despite the promise of modeling structured dependencies
  in documents, several existing text hashing methods lack an efficient mechanism to
  incorporate such vital information. Additionally, the desired characteristics of an
  ideal hash function, such as robustness to noise, low quantization error and bit balance/uncorrelation,
  are not effectively learned with existing methods. This is because of the requirement
  to either tune additional hyper-parameters or optimize these heuristically and explicitly
  constructed cost functions. In this paper, we propose a Denoising Adversarial Binary
  Autoencoder (DABA) model which presents a novel representation learning framework
  that captures structured representation of text documents in the learned hash function.
  Also, adversarial training provides an alternative direction to implicitly learn a
  hash function that captures all the desired characteristics of an ideal hash function.
  Essentially, DABA adopts a novel single-optimization adversarial training procedure
  that minimizes the Wasserstein distance in its primal domain to regularize the encoderâ€™s
  output of either a recurrent neural network or a convolutional autoencoder. We empirically
  demonstrate the effectiveness of our proposed method in capturing the intrinsic semantic
  manifold of the related documents. The proposed method outperforms the current state-of-the-art
  shallow and deep unsupervised hashing methods for the document retrieval task on several
  prominent document collections.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2020efficient</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{WWW}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3366423.3380150}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3366423.3380150}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://people.cs.vt.edu/~reddy/papers/WWW20a.pdf}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2020efficient.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient Implicit Unsupervised Text Hashing Using Adversarial Autoencoder}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450370233}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3366423.3380150}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The Web Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{684â€“694}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{autoencoder, Hashing, adversarial training, deep learning.}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Taipei, Taiwan}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{WWW '20}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">arXiv</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2020imagegen" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">arXiv</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Image Generation Via Minimizing FrÃ©chet Distance in Discriminator Feature Space         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://en.wikipedia.org/wiki/Carl_Philipp_Emanuel_Bach" target="_blank">Fengjiao Wang</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://www.keerthis.com/" target="_blank">Sathiya K Selvaraj</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://avradeep1.github.io/" target="_blank">Avradeep Bhowmik</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2003.11774</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doan2020imagegen</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Image Generation Via Minimizing FrÃ©chet Distance in Discriminator Feature Space}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Manchanda, Saurav and Wang, Fengjiao and Selvaraj, Sathiya K and Bhowmik, Avradeep and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2003.11774}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">arXiv</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2020imagehash" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">arXiv</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=Mkaq4VYAAAAJ&amp;hl=en" target="_blank">Sarkhan Badirli</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2003.00134</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">doan2020imagehash</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Manchanda, Saurav and Badirli, Sarkhan and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2003.00134}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">arXiv</abbr>
    
    </div>
  
  </div> -->

  <div id="manchanda2020regression" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">arXiv</abbr>
            
          
          </span>
        
        
        
        Regression via implicit models and optimal transport cost minimization         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Pranjul Yadav,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://www.keerthis.com/" target="_blank">Sathiya K Selvaraj</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2003.01296</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">manchanda2020regression</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regression via implicit models and optimal transport cost minimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Manchanda, Saurav and Doan, Khoa D and Yadav, Pranjul and Selvaraj, Sathiya K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2003.01296}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">arXiv</abbr>
    
    </div>
  
  </div> -->

  <div id="badirli2020gradient" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">arXiv</abbr>
            
          
          </span>
        
        
        
        Gradient boosting neural networks: Grownet         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=Mkaq4VYAAAAJ&amp;hl=en" target="_blank">Sarkhan Badirli</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://xuanqing94.github.io/" target="_blank">Xuanqing Liu</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://zmxing.github.io/" target="_blank">Zhengming Xing</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://avradeep1.github.io/" target="_blank">Avradeep Bhowmik</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://www.keerthis.com/" target="_blank">Sathiya K Selvaraj</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2002.07971</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2002.07971.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      <a href="https://github.com/sbadirli/GrowNet" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A novel gradient boosting framework is proposed where shallow neural networks are employed as ``weak learners''. General loss functions are considered under this unified framework with specific examples presented for classification, regression, and learning to rank. A fully corrective step is incorporated to remedy the pitfall of greedy function approximation of classic gradient boosting decision tree. The proposed model rendered outperforming results against state-of-the-art boosting methods in all three tasks on multiple datasets. An ablation study is performed to shed light on the effect of each model components and model hyperparameters.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">badirli2020gradient</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2002.07971}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/sbadirli/GrowNet}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2002.07971.pdf}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{badirli2020gradient.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gradient boosting neural networks: Grownet}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Badirli, Sarkhan and Liu, Xuanqing and Xing, Zhengming and Bhowmik, Avradeep and Doan, Khoa D and Selvaraj, Sathiya K}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2002.07971}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2019&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">BigData</abbr>
    
    </div>
  
  </div> -->

  <div id="manchanda2019targeted" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">BigData</abbr>
            
          
          </span>
        
        
        
        Targeted display advertising: the case of preferential attachment         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://gurdaspuriya.github.io/" target="_blank">Saurav Manchanda</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Pranjul Yadav,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://www.keerthis.com/" target="_blank">Sathiya K Selvaraj</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2019 IEEE International Conference on Big Data</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">manchanda2019targeted</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{BigData}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Targeted display advertising: the case of preferential attachment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Manchanda, Saurav and Yadav, Pranjul and Doan, Khoa D and Selvaraj, Sathiya K}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2019 IEEE International Conference on Big Data}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1868--1877}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">CIKM</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2019adversarial" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">CIKM</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Adversarial Factorization Autoencoder for Look-Alike Modeling         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Pranjul Yadav,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://dmkd.cs.vt.edu/papers/CIKM19.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Digital advertising is performed in multiple ways, for e.g., contextual, display-based
  and search-based advertising. Across these avenues, the primary goal of the advertiser
  is to maximize the return on investment. To realize this, the advertiser often aims
  to target the advertisements towards a targeted set of audience as this set has a
  high likelihood to respond positively towards the advertisements. One such form of
  tailored and personalized, targeted advertising is known as look-alike modeling, where
  the advertiser provides a set of seed users and expects the machine learning model
  to identify a new set of users such that the newly identified set is similar to the
  seed-set with respect to the online purchasing activity. Existing look-alike modeling
  techniques (i.e., similarity-based and regression-based) suffer from serious limitations
  due to the implicit constraints induced during modeling. In addition, the high-dimensional
  and sparse nature of the advertising data increases the complexity. To overcome these
  limitations, in this paper, we propose a novel Adversarial Factorization Autoencoder
  that can efficiently learn a binary mapping from sparse, high-dimensional data to
  a binary address space through the use of an adversarial training procedure. We demonstrate
  the effectiveness of our proposed approach on a dataset obtained from a real-world
  setting and also systematically compare the performance of our proposed approach with
  existing look-alike modeling baselines.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2019adversarial</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{CIKM}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://dmkd.cs.vt.edu/papers/CIKM19.pdf}</span><span class="p">,</span>
  <span class="na">teaser</span> <span class="p">=</span> <span class="s">{doan2019adversarial.png}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Yadav, Pranjul and Reddy, Chandan K}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adversarial Factorization Autoencoder for Look-Alike Modeling}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450369763}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3357384.3357807}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3357384.3357807}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 28th ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2803â€“2812}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{deep learning, autoencoder, hashing, factorization, adversarial training, look-alike modeling}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Beijing, China}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '19}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">PAKDD</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2019attentive" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">PAKDD</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        An Attentive Spatio-Temporal Neural Model for Successive Point of Interest Recommendation.         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://scholar.google.com/citations?user=B11lRXUAAAAJ&amp;hl=en" target="_blank">Guolei Yang</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="https://people.cs.vt.edu/reddy/index.html" target="_blank">Chandan K Reddy</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2019 Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2017&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">BigData</abbr>
    
    </div>
  
  </div> -->

  <div id="kuo2017quest" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">BigData</abbr>
            
          
          </span>
        
        
        
        Quest for Value in Big Earth Data         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.linkedin.com/in/kwo-sen-kuo-9a12b536" target="_blank">Kwo-Sen Kuo</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Amidu O Oloso,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Mike L Rilee,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://science.gsfc.nasa.gov/sed/bio/thomas.l.clune" target="_blank">Thomas L Clune</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://vis.unl.edu/~yu/" target="_blank">Hongfeng Yu</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In EGU General Assembly Conference Abstracts</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kuo2017quest</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{BigData}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Quest for Value in Big Earth Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kuo, Kwo-Sen and Oloso, Amidu O and Rilee, Mike L and Doan, Khoa D and Clune, Thomas L and Yu, Hongfeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{EGU General Assembly Conference Abstracts}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8413}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2016&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">BigData</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2016evaluating" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">BigData</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Evaluating the impact of data placement to spark and SciDB with an Earth Science use case         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Amidu O Oloso,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.linkedin.com/in/kwo-sen-kuo-9a12b536" target="_blank">Kwo-Sen Kuo</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://science.gsfc.nasa.gov/sed/bio/thomas.l.clune" target="_blank">Thomas L Clune</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="http://vis.unl.edu/~yu/" target="_blank">Hongfeng Yu</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Brian Nelson,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and Jian Zhang
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2016 IEEE International Conference on Big Data</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2016evaluating</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{BigData}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evaluating the impact of data placement to spark and SciDB with an Earth Science use case}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Oloso, Amidu O and Kuo, Kwo-Sen and Clune, Thomas L and Yu, Hongfeng and Nelson, Brian and Zhang, Jian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2016 IEEE International Conference on Big Data}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{341--346}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">IGARSS</abbr>
    
    </div>
  
  </div> -->

  <div id="kuo2016implications" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">IGARSS</abbr>
            
          
          </span>
        
        
        
        Implications of data placement strategy to Big Data technologies based on shared-nothing architecture for geosciences         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.linkedin.com/in/kwo-sen-kuo-9a12b536" target="_blank">Kwo-Sen Kuo</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Amidu Oloso,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://science.gsfc.nasa.gov/sed/bio/thomas.l.clune" target="_blank">Thomas L Clune</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  and <a href="http://vis.unl.edu/~yu/" target="_blank">Hongfeng Yu</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kuo2016implications</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{IGARSS}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Implications of data placement strategy to Big Data technologies based on shared-nothing architecture for geosciences}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kuo, Kwo-Sen and Oloso, Amidu and Doan, Khoa D and Clune, Thomas L and Yu, Hongfeng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7605--7607}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2015&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">AGU</abbr>
    
    </div>
  
  </div> -->

  <div id="clune2015scidb" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">AGU</abbr>
            
          
          </span>
        
        
        
        SciDB versus Spark: A preliminary comparison based on an Earth science use case         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://science.gsfc.nasa.gov/sed/bio/thomas.l.clune" target="_blank">Thomas Clune</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.linkedin.com/in/kwo-sen-kuo-9a12b536" target="_blank">Kwo-Sen Kuo</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and Amidu Oloso
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In AGU Fall Meeting Abstracts</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">clune2015scidb</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AGU}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SciDB versus Spark: A preliminary comparison based on an Earth science use case}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clune, Thomas and Kuo, Kwo-Sen and Doan, Khoa D and Oloso, Amidu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AGU Fall Meeting Abstracts}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2014&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">BigData</abbr>
    
    </div>
  
  </div> -->

  <div id="doan2014performance" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">BigData</abbr>
            
          
          </span>
        
        
        <span class="d-inline-block" tabindex="0" data-toggle="tooltip" title="Majority of work done or significant contribution by MAIL/SAIL members!">
          <abbr class="badge bg-danger"><i class="bi bi-check2"></i></abbr>
        </span>

        
        
        Performance comparison of big-data technologies in locating intersections in satellite ground tracks         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
          
            
              
                <u>Khoa D Doan</u>,
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    Amidu Oloso,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://www.linkedin.com/in/kwo-sen-kuo-9a12b536" target="_blank">Kwo-Sen Kuo</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
                
                
          
          
            
              
                
                  
                    <a href="https://science.gsfc.nasa.gov/sed/bio/thomas.l.clune" target="_blank">Thomas L Clune</a>,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and LLC Bayesics
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2014 ASE BigData/SocialInformatics/PASSAT/BioMedCom Conference</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">doan2014performance</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{BigData}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Performance comparison of big-data technologies in locating intersections in satellite ground tracks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Doan, Khoa D and Oloso, Amidu and Kuo, Kwo-Sen and Clune, Thomas L and Bayesics, LLC}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2014 ASE BigData/SocialInformatics/PASSAT/BioMedCom Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Citeseer}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
    <!-- <h2 class="pyear">2013&nbsp;&nbsp;</h2> -->
    <!-- <p>&nbsp;</p> -->
    <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-1 abbr">
  
    <div>
    
    <abbr class="badge">AGU</abbr>
    
    </div>
  
  </div> -->

  <div id="kuo2013demonstration" class="col-sm-12">
    
    
    

    
      <div class="title">
        
          <span class="abbr">
          
            
              <abbr class="badge">AGU</abbr>
            
          
          </span>
        
        
        
        A Demonstration of Big Data Technology for Data Intensive Earth Science         
        
      </div>
      <div class="author">
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    K Kuo,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
            
              
            
          
          
            
              
                
                  
                    T Clune,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    R Ramachandran,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    J Rushing,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    G Fekete,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    A Lin,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    KD Doan,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  
                    AO Oloso,
                  
                
            
                
              
            
          
        
          
          
          

          
          
          
          
          
          
          
            
              
                
                  and D Duffy
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In AGU Fall Meeting Abstracts</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
    
    
    
    
    
    
        
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kuo2013demonstration</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{AGU}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Demonstration of Big Data Technology for Data Intensive Earth Science}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kuo, K and Clune, T and Ramachandran, R and Rushing, J and Fekete, G and Lin, A and Doan, KD and Oloso, AO and Duffy, D}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AGU Fall Meeting Abstracts}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
  
</div>

</div>

<!-- <a href="https://scholar.google.com/citations?user=Zz2hMgcAAAAJ&hl=en">Google Scholar</a>. -->

  </article>

</div>

    </div>

    <!-- Footer -->

    
<div class="container mt-0">
  <em>The brick walls are there for a reason. The brick walls are not there to keep us out. The brick walls are there to give us a chance to show how badly we want something</em> -- <a href="https://en.wikipedia.org/wiki/Randy_Pausch">Randy Pausch</a>

</div>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=n&d=6Aazaa3W3ib-sAIfPEQYBd0A-PM2ZbkZfCUcYo54GsE&co=233d4d'></script>


<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2026 Khoa D Doan.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
